{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "WQvVJT8KMI0Z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import pandas as pd\n",
        "from scipy.stats import zscore\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "gAtAUkY0MPNC"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/m3gofriends/My-Machine-and-Deep-Learning-Template-main/main/Data/CSV/wcbreast_wdbc.csv\",\n",
        "    na_values=['NA', '?'])"
      ],
      "metadata": {
        "id": "vLFwihMGMRun"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "nGqadU_lMkaM",
        "outputId": "2960554f-8d43-42d2-af0a-c7ef60cdc64c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id diagnosis  mean_radius  mean_texture  mean_perimeter  mean_area  \\\n",
              "0    842302         M        17.99         10.38          122.80     1001.0   \n",
              "1    842517         M        20.57         17.77          132.90     1326.0   \n",
              "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3  84348301         M        11.42         20.38           77.58      386.1   \n",
              "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   mean_smoothness  mean_compactness  mean_concavity  mean_concave_points  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   ...  worst_radius  worst_texture  worst_perimeter  worst_area  \\\n",
              "0  ...         25.38          17.33           184.60      2019.0   \n",
              "1  ...         24.99          23.41           158.80      1956.0   \n",
              "2  ...         23.57          25.53           152.50      1709.0   \n",
              "3  ...         14.91          26.50            98.87       567.7   \n",
              "4  ...         22.54          16.67           152.20      1575.0   \n",
              "\n",
              "   worst_smoothness  worst_compactness  worst_concavity  worst_concave_points  \\\n",
              "0            0.1622             0.6656           0.7119                0.2654   \n",
              "1            0.1238             0.1866           0.2416                0.1860   \n",
              "2            0.1444             0.4245           0.4504                0.2430   \n",
              "3            0.2098             0.8663           0.6869                0.2575   \n",
              "4            0.1374             0.2050           0.4000                0.1625   \n",
              "\n",
              "   worst_symmetry  worst_fractal_dimension  \n",
              "0          0.4601                  0.11890  \n",
              "1          0.2750                  0.08902  \n",
              "2          0.3613                  0.08758  \n",
              "3          0.6638                  0.17300  \n",
              "4          0.2364                  0.07678  \n",
              "\n",
              "[5 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61383f3b-9ead-48a2-b647-1d3a2948da0b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>mean_radius</th>\n",
              "      <th>mean_texture</th>\n",
              "      <th>mean_perimeter</th>\n",
              "      <th>mean_area</th>\n",
              "      <th>mean_smoothness</th>\n",
              "      <th>mean_compactness</th>\n",
              "      <th>mean_concavity</th>\n",
              "      <th>mean_concave_points</th>\n",
              "      <th>...</th>\n",
              "      <th>worst_radius</th>\n",
              "      <th>worst_texture</th>\n",
              "      <th>worst_perimeter</th>\n",
              "      <th>worst_area</th>\n",
              "      <th>worst_smoothness</th>\n",
              "      <th>worst_compactness</th>\n",
              "      <th>worst_concavity</th>\n",
              "      <th>worst_concave_points</th>\n",
              "      <th>worst_symmetry</th>\n",
              "      <th>worst_fractal_dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 32 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61383f3b-9ead-48a2-b647-1d3a2948da0b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-61383f3b-9ead-48a2-b647-1d3a2948da0b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-61383f3b-9ead-48a2-b647-1d3a2948da0b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to numpy - Classification\n",
        "x_columns = df.columns.drop('diagnosis').drop('id')\n",
        "for col in x_columns:\n",
        "    df[col] = zscore(df[col])\n",
        "\n",
        "x = df[x_columns].values\n",
        "y = df['diagnosis'].map({'M':1,\"B\":0}).values # Binary classification, M is 1 and B is 0 "
      ],
      "metadata": {
        "id": "kPCCzSnuMkmJ"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4wQ9_eVMlz5",
        "outputId": "a46ceefa-70b5-4d60-f9cb-efe6a6abd3de"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569, 30)\n",
            "(569,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "TqjwITJsMnKN",
        "outputId": "d4d69003-6da7-42c7-caab-138ba5cc6f71"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id diagnosis  mean_radius  mean_texture  mean_perimeter  mean_area  \\\n",
              "0    842302         M     1.097064     -2.073335        1.269934   0.984375   \n",
              "1    842517         M     1.829821     -0.353632        1.685955   1.908708   \n",
              "2  84300903         M     1.579888      0.456187        1.566503   1.558884   \n",
              "3  84348301         M    -0.768909      0.253732       -0.592687  -0.764464   \n",
              "4  84358402         M     1.750297     -1.151816        1.776573   1.826229   \n",
              "\n",
              "   mean_smoothness  mean_compactness  mean_concavity  mean_concave_points  \\\n",
              "0         1.568466          3.283515        2.652874             2.532475   \n",
              "1        -0.826962         -0.487072       -0.023846             0.548144   \n",
              "2         0.942210          1.052926        1.363478             2.037231   \n",
              "3         3.283553          3.402909        1.915897             1.451707   \n",
              "4         0.280372          0.539340        1.371011             1.428493   \n",
              "\n",
              "   ...  worst_radius  worst_texture  worst_perimeter  worst_area  \\\n",
              "0  ...      1.886690      -1.359293         2.303601    2.001237   \n",
              "1  ...      1.805927      -0.369203         1.535126    1.890489   \n",
              "2  ...      1.511870      -0.023974         1.347475    1.456285   \n",
              "3  ...     -0.281464       0.133984        -0.249939   -0.550021   \n",
              "4  ...      1.298575      -1.466770         1.338539    1.220724   \n",
              "\n",
              "   worst_smoothness  worst_compactness  worst_concavity  worst_concave_points  \\\n",
              "0          1.307686           2.616665         2.109526              2.296076   \n",
              "1         -0.375612          -0.430444        -0.146749              1.087084   \n",
              "2          0.527407           1.082932         0.854974              1.955000   \n",
              "3          3.394275           3.893397         1.989588              2.175786   \n",
              "4          0.220556          -0.313395         0.613179              0.729259   \n",
              "\n",
              "   worst_symmetry  worst_fractal_dimension  \n",
              "0        2.750622                 1.937015  \n",
              "1       -0.243890                 0.281190  \n",
              "2        1.152255                 0.201391  \n",
              "3        6.046041                 4.935010  \n",
              "4       -0.868353                -0.397100  \n",
              "\n",
              "[5 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5dd365ea-bb16-4d43-9b81-4bc638103eed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>mean_radius</th>\n",
              "      <th>mean_texture</th>\n",
              "      <th>mean_perimeter</th>\n",
              "      <th>mean_area</th>\n",
              "      <th>mean_smoothness</th>\n",
              "      <th>mean_compactness</th>\n",
              "      <th>mean_concavity</th>\n",
              "      <th>mean_concave_points</th>\n",
              "      <th>...</th>\n",
              "      <th>worst_radius</th>\n",
              "      <th>worst_texture</th>\n",
              "      <th>worst_perimeter</th>\n",
              "      <th>worst_area</th>\n",
              "      <th>worst_smoothness</th>\n",
              "      <th>worst_compactness</th>\n",
              "      <th>worst_concavity</th>\n",
              "      <th>worst_concave_points</th>\n",
              "      <th>worst_symmetry</th>\n",
              "      <th>worst_fractal_dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>1.097064</td>\n",
              "      <td>-2.073335</td>\n",
              "      <td>1.269934</td>\n",
              "      <td>0.984375</td>\n",
              "      <td>1.568466</td>\n",
              "      <td>3.283515</td>\n",
              "      <td>2.652874</td>\n",
              "      <td>2.532475</td>\n",
              "      <td>...</td>\n",
              "      <td>1.886690</td>\n",
              "      <td>-1.359293</td>\n",
              "      <td>2.303601</td>\n",
              "      <td>2.001237</td>\n",
              "      <td>1.307686</td>\n",
              "      <td>2.616665</td>\n",
              "      <td>2.109526</td>\n",
              "      <td>2.296076</td>\n",
              "      <td>2.750622</td>\n",
              "      <td>1.937015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>1.829821</td>\n",
              "      <td>-0.353632</td>\n",
              "      <td>1.685955</td>\n",
              "      <td>1.908708</td>\n",
              "      <td>-0.826962</td>\n",
              "      <td>-0.487072</td>\n",
              "      <td>-0.023846</td>\n",
              "      <td>0.548144</td>\n",
              "      <td>...</td>\n",
              "      <td>1.805927</td>\n",
              "      <td>-0.369203</td>\n",
              "      <td>1.535126</td>\n",
              "      <td>1.890489</td>\n",
              "      <td>-0.375612</td>\n",
              "      <td>-0.430444</td>\n",
              "      <td>-0.146749</td>\n",
              "      <td>1.087084</td>\n",
              "      <td>-0.243890</td>\n",
              "      <td>0.281190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>1.579888</td>\n",
              "      <td>0.456187</td>\n",
              "      <td>1.566503</td>\n",
              "      <td>1.558884</td>\n",
              "      <td>0.942210</td>\n",
              "      <td>1.052926</td>\n",
              "      <td>1.363478</td>\n",
              "      <td>2.037231</td>\n",
              "      <td>...</td>\n",
              "      <td>1.511870</td>\n",
              "      <td>-0.023974</td>\n",
              "      <td>1.347475</td>\n",
              "      <td>1.456285</td>\n",
              "      <td>0.527407</td>\n",
              "      <td>1.082932</td>\n",
              "      <td>0.854974</td>\n",
              "      <td>1.955000</td>\n",
              "      <td>1.152255</td>\n",
              "      <td>0.201391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>-0.768909</td>\n",
              "      <td>0.253732</td>\n",
              "      <td>-0.592687</td>\n",
              "      <td>-0.764464</td>\n",
              "      <td>3.283553</td>\n",
              "      <td>3.402909</td>\n",
              "      <td>1.915897</td>\n",
              "      <td>1.451707</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.281464</td>\n",
              "      <td>0.133984</td>\n",
              "      <td>-0.249939</td>\n",
              "      <td>-0.550021</td>\n",
              "      <td>3.394275</td>\n",
              "      <td>3.893397</td>\n",
              "      <td>1.989588</td>\n",
              "      <td>2.175786</td>\n",
              "      <td>6.046041</td>\n",
              "      <td>4.935010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>1.750297</td>\n",
              "      <td>-1.151816</td>\n",
              "      <td>1.776573</td>\n",
              "      <td>1.826229</td>\n",
              "      <td>0.280372</td>\n",
              "      <td>0.539340</td>\n",
              "      <td>1.371011</td>\n",
              "      <td>1.428493</td>\n",
              "      <td>...</td>\n",
              "      <td>1.298575</td>\n",
              "      <td>-1.466770</td>\n",
              "      <td>1.338539</td>\n",
              "      <td>1.220724</td>\n",
              "      <td>0.220556</td>\n",
              "      <td>-0.313395</td>\n",
              "      <td>0.613179</td>\n",
              "      <td>0.729259</td>\n",
              "      <td>-0.868353</td>\n",
              "      <td>-0.397100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 32 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5dd365ea-bb16-4d43-9b81-4bc638103eed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5dd365ea-bb16-4d43-9b81-4bc638103eed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5dd365ea-bb16-4d43-9b81-4bc638103eed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into train/test\n",
        "x_train, y_train, x_test, y_test = train_test_split(x, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "Y5c3Q6biMoSZ"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "print(x_train.shape)\n",
        "print(x_test.shape) # Label\n",
        "\n",
        "# Test\n",
        "print(y_train.shape)\n",
        "print(y_test.shape) # Label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTBKNrp8MqsN",
        "outputId": "790a94dc-c30f-4f1e-8a6b-c4a6ccba8715"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(455, 30)\n",
            "(455,)\n",
            "(114, 30)\n",
            "(114,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.Tensor(x_train).cuda()\n",
        "x_test = torch.Tensor(x_test).cuda()\n",
        "y_train = torch.Tensor(y_train).cuda()\n",
        "y_test = torch.Tensor(y_test).cuda()"
      ],
      "metadata": {
        "id": "fYFu5S0dMuba"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(30, 256)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc3 = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        return torch.sigmoid(x)"
      ],
      "metadata": {
        "id": "pR2HPustMwyx"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network = Net()\n",
        "network.cuda()\n",
        "optimizer = torch.optim.Adam(network.parameters(), lr=1e-2, weight_decay=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=5, verbose=True, min_lr=1e-10)"
      ],
      "metadata": {
        "id": "i6HbsR3uN30t"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "train_counter = []\n",
        "test_accuracy = []\n",
        "test_losses = []"
      ],
      "metadata": {
        "id": "kWxfWe0fN9fI"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "  network.train()\n",
        "  optimizer.zero_grad()\n",
        "  pred = network(x_train)\n",
        "  loss = F.binary_cross_entropy(pred.view(-1), x_test)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  #scheduler.step(loss)\n",
        "\n",
        "  print('Train Epoch : {}, Loss : {:.6f}'.format(epoch, loss.item()))\n",
        "  train_losses.append(loss.item())\n",
        "  train_counter.append(epoch)"
      ],
      "metadata": {
        "id": "0wJijYDzOCcX"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(epoch):\n",
        "  correct = 0\n",
        "  network.eval()\n",
        "  with torch.no_grad():\n",
        "    pred = network(y_train)\n",
        "    pred = torch.where(pred.view(-1) > 0.5, 1.0, 0.0) # If value > 0.5, value = 1.0, else value = 0.0\n",
        "    correct = torch.eq(pred, y_test).sum().item()\n",
        "    loss = F.binary_cross_entropy(pred.view(-1), y_test)\n",
        "    scheduler.step(loss)\n",
        "\n",
        "  print('Test Epoch : {}, Loss ; {:.6f}, Accuracy : [{}/{}] {:.1f}%'.format(epoch, loss.item(), correct , len(y_test), 100 * correct / len(y_test)))\n",
        "  test_accuracy.append(100 * correct / len(y_test))\n",
        "  test_losses.append(loss.item())"
      ],
      "metadata": {
        "id": "pk1XNCc2ODo5"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, epochs+1):\n",
        "  train(epoch)\n",
        "  test(epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Prg_xgHzOFIX",
        "outputId": "49907912-f7f9-4d87-83dd-1a07936564d5"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch : 1, Loss : 0.690641\n",
            "Test Epoch : 1, Loss ; 6.140351, Accuracy : [107/114] 93.9%\n",
            "Train Epoch : 2, Loss : 0.356427\n",
            "Test Epoch : 2, Loss ; 5.263158, Accuracy : [108/114] 94.7%\n",
            "Train Epoch : 3, Loss : 0.192206\n",
            "Test Epoch : 3, Loss ; 4.385965, Accuracy : [109/114] 95.6%\n",
            "Train Epoch : 4, Loss : 0.133427\n",
            "Test Epoch : 4, Loss ; 1.754386, Accuracy : [112/114] 98.2%\n",
            "Train Epoch : 5, Loss : 0.094985\n",
            "Test Epoch : 5, Loss ; 0.877193, Accuracy : [113/114] 99.1%\n",
            "Train Epoch : 6, Loss : 0.082541\n",
            "Test Epoch : 6, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 7, Loss : 0.092966\n",
            "Test Epoch : 7, Loss ; 0.877193, Accuracy : [113/114] 99.1%\n",
            "Train Epoch : 8, Loss : 0.112942\n",
            "Test Epoch : 8, Loss ; 0.877193, Accuracy : [113/114] 99.1%\n",
            "Train Epoch : 9, Loss : 0.085015\n",
            "Test Epoch : 9, Loss ; 0.877193, Accuracy : [113/114] 99.1%\n",
            "Train Epoch : 10, Loss : 0.064602\n",
            "Test Epoch : 10, Loss ; 0.877193, Accuracy : [113/114] 99.1%\n",
            "Train Epoch : 11, Loss : 0.060252\n",
            "Test Epoch : 11, Loss ; 0.877193, Accuracy : [113/114] 99.1%\n",
            "Train Epoch : 12, Loss : 0.068220\n",
            "Epoch 00012: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Test Epoch : 12, Loss ; 0.877193, Accuracy : [113/114] 99.1%\n",
            "Train Epoch : 13, Loss : 0.057221\n",
            "Test Epoch : 13, Loss ; 0.877193, Accuracy : [113/114] 99.1%\n",
            "Train Epoch : 14, Loss : 0.053120\n",
            "Test Epoch : 14, Loss ; 0.877193, Accuracy : [113/114] 99.1%\n",
            "Train Epoch : 15, Loss : 0.051059\n",
            "Test Epoch : 15, Loss ; 0.877193, Accuracy : [113/114] 99.1%\n",
            "Train Epoch : 16, Loss : 0.045551\n",
            "Test Epoch : 16, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 17, Loss : 0.036724\n",
            "Test Epoch : 17, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 18, Loss : 0.042691\n",
            "Epoch 00018: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Test Epoch : 18, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 19, Loss : 0.036954\n",
            "Test Epoch : 19, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 20, Loss : 0.042680\n",
            "Test Epoch : 20, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 21, Loss : 0.036526\n",
            "Test Epoch : 21, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 22, Loss : 0.031365\n",
            "Test Epoch : 22, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 23, Loss : 0.032431\n",
            "Test Epoch : 23, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 24, Loss : 0.033134\n",
            "Epoch 00024: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Test Epoch : 24, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 25, Loss : 0.028088\n",
            "Test Epoch : 25, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 26, Loss : 0.029365\n",
            "Test Epoch : 26, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 27, Loss : 0.028450\n",
            "Test Epoch : 27, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 28, Loss : 0.035492\n",
            "Test Epoch : 28, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 29, Loss : 0.024619\n",
            "Test Epoch : 29, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 30, Loss : 0.027085\n",
            "Epoch 00030: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Test Epoch : 30, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 31, Loss : 0.029689\n",
            "Test Epoch : 31, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 32, Loss : 0.026392\n",
            "Test Epoch : 32, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 33, Loss : 0.025162\n",
            "Test Epoch : 33, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 34, Loss : 0.031858\n",
            "Test Epoch : 34, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 35, Loss : 0.036071\n",
            "Test Epoch : 35, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 36, Loss : 0.030167\n",
            "Epoch 00036: reducing learning rate of group 0 to 3.1250e-04.\n",
            "Test Epoch : 36, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 37, Loss : 0.025022\n",
            "Test Epoch : 37, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 38, Loss : 0.025919\n",
            "Test Epoch : 38, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 39, Loss : 0.028907\n",
            "Test Epoch : 39, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 40, Loss : 0.022413\n",
            "Test Epoch : 40, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 41, Loss : 0.023229\n",
            "Test Epoch : 41, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 42, Loss : 0.025079\n",
            "Epoch 00042: reducing learning rate of group 0 to 1.5625e-04.\n",
            "Test Epoch : 42, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 43, Loss : 0.027818\n",
            "Test Epoch : 43, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 44, Loss : 0.028913\n",
            "Test Epoch : 44, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 45, Loss : 0.028134\n",
            "Test Epoch : 45, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 46, Loss : 0.024777\n",
            "Test Epoch : 46, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 47, Loss : 0.032924\n",
            "Test Epoch : 47, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 48, Loss : 0.028740\n",
            "Epoch 00048: reducing learning rate of group 0 to 7.8125e-05.\n",
            "Test Epoch : 48, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 49, Loss : 0.030995\n",
            "Test Epoch : 49, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 50, Loss : 0.030864\n",
            "Test Epoch : 50, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 51, Loss : 0.026751\n",
            "Test Epoch : 51, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 52, Loss : 0.031828\n",
            "Test Epoch : 52, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 53, Loss : 0.028303\n",
            "Test Epoch : 53, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 54, Loss : 0.032098\n",
            "Epoch 00054: reducing learning rate of group 0 to 3.9063e-05.\n",
            "Test Epoch : 54, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 55, Loss : 0.033366\n",
            "Test Epoch : 55, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 56, Loss : 0.034085\n",
            "Test Epoch : 56, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 57, Loss : 0.025622\n",
            "Test Epoch : 57, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 58, Loss : 0.031408\n",
            "Test Epoch : 58, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 59, Loss : 0.025219\n",
            "Test Epoch : 59, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 60, Loss : 0.027138\n",
            "Epoch 00060: reducing learning rate of group 0 to 1.9531e-05.\n",
            "Test Epoch : 60, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 61, Loss : 0.032789\n",
            "Test Epoch : 61, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 62, Loss : 0.026886\n",
            "Test Epoch : 62, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 63, Loss : 0.025853\n",
            "Test Epoch : 63, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 64, Loss : 0.031716\n",
            "Test Epoch : 64, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 65, Loss : 0.025719\n",
            "Test Epoch : 65, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 66, Loss : 0.028607\n",
            "Epoch 00066: reducing learning rate of group 0 to 9.7656e-06.\n",
            "Test Epoch : 66, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 67, Loss : 0.022176\n",
            "Test Epoch : 67, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 68, Loss : 0.031476\n",
            "Test Epoch : 68, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 69, Loss : 0.025967\n",
            "Test Epoch : 69, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 70, Loss : 0.025304\n",
            "Test Epoch : 70, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 71, Loss : 0.027455\n",
            "Test Epoch : 71, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 72, Loss : 0.038646\n",
            "Epoch 00072: reducing learning rate of group 0 to 4.8828e-06.\n",
            "Test Epoch : 72, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 73, Loss : 0.027206\n",
            "Test Epoch : 73, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 74, Loss : 0.030452\n",
            "Test Epoch : 74, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 75, Loss : 0.027695\n",
            "Test Epoch : 75, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 76, Loss : 0.027124\n",
            "Test Epoch : 76, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 77, Loss : 0.035976\n",
            "Test Epoch : 77, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 78, Loss : 0.030441\n",
            "Epoch 00078: reducing learning rate of group 0 to 2.4414e-06.\n",
            "Test Epoch : 78, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 79, Loss : 0.030117\n",
            "Test Epoch : 79, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 80, Loss : 0.028941\n",
            "Test Epoch : 80, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 81, Loss : 0.022899\n",
            "Test Epoch : 81, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 82, Loss : 0.018405\n",
            "Test Epoch : 82, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 83, Loss : 0.026672\n",
            "Test Epoch : 83, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 84, Loss : 0.030727\n",
            "Epoch 00084: reducing learning rate of group 0 to 1.2207e-06.\n",
            "Test Epoch : 84, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 85, Loss : 0.031142\n",
            "Test Epoch : 85, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 86, Loss : 0.027163\n",
            "Test Epoch : 86, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 87, Loss : 0.023122\n",
            "Test Epoch : 87, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 88, Loss : 0.027978\n",
            "Test Epoch : 88, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 89, Loss : 0.027521\n",
            "Test Epoch : 89, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 90, Loss : 0.025452\n",
            "Epoch 00090: reducing learning rate of group 0 to 6.1035e-07.\n",
            "Test Epoch : 90, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 91, Loss : 0.031526\n",
            "Test Epoch : 91, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 92, Loss : 0.033201\n",
            "Test Epoch : 92, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 93, Loss : 0.031513\n",
            "Test Epoch : 93, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 94, Loss : 0.025594\n",
            "Test Epoch : 94, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 95, Loss : 0.023655\n",
            "Test Epoch : 95, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 96, Loss : 0.033229\n",
            "Epoch 00096: reducing learning rate of group 0 to 3.0518e-07.\n",
            "Test Epoch : 96, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 97, Loss : 0.033865\n",
            "Test Epoch : 97, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 98, Loss : 0.028329\n",
            "Test Epoch : 98, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 99, Loss : 0.024748\n",
            "Test Epoch : 99, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n",
            "Train Epoch : 100, Loss : 0.028948\n",
            "Test Epoch : 100, Loss ; 0.000000, Accuracy : [114/114] 100.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(train_counter, train_losses, color='red')\n",
        "plt.plot(train_counter, test_losses, color='blue')\n",
        "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "GA41vH0QOL-Y",
        "outputId": "1b7e8935-573e-447c-cbdd-7be6597a3ce0"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 71
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(train_counter, test_accuracy, color='blue')\n",
        "plt.legend(['Test Accuracy'], loc='lower right')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "428erCd0OMMI",
        "outputId": "62ad2ff3-f7e9-4f47-c260-60d97d065500"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 72
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}